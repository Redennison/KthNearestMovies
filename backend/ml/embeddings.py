# -*- coding: utf-8 -*-
"""movie_recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dlmnFoA4-MoPC2Lcfc_YfXqrebODWpLH
"""

import torch
from google.colab import drive
from transformers import BertTokenizer, BertModel
import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import MultiLabelBinarizer

movies_csv = 'top_250_movies.csv'
movies_df = pd.read_csv(movies_csv)

# Load pre-trained BERT model and tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')

# Set model to evaluation mode
model.eval()

descriptions = movies_df['description'].astype(str).tolist()

# Define a function to generate embeddings in batches
def get_embeddings_batch(descriptions, batch_size=32):
    embeddings = []
    for i in range(0, len(descriptions), batch_size):
        batch_descriptions = descriptions[i:i+batch_size]
        encoded_inputs = tokenizer(batch_descriptions, return_tensors='pt', padding=True, truncation=True, max_length=128)

        with torch.no_grad():
            outputs = model(**encoded_inputs)

        # Get the CLS token embeddings
        cls_embeddings = outputs.last_hidden_state[:, 0, :].numpy()
        embeddings.append(cls_embeddings)

        print(f'batch {(i)/batch_size+1} of {len(descriptions)/batch_size} completed')

    # Concatenate the batch embeddings
    embeddings = np.vstack(embeddings)
    return embeddings

# Assuming 'descriptions' contains all your movie descriptions
batch_embeddings = get_embeddings_batch(descriptions, batch_size=32)

mlb = MultiLabelBinarizer()

# Split categories into list
movies_df['categories_split'] = movies_df['genre'].apply(lambda x: x.split(', '))

# Fit and transform the categories into one-hot encoded format
categories_one_hot = mlb.fit_transform(movies_df['categories_split'])

# Convert the one-hot encoded categories into a DataFrame
categories_df = pd.DataFrame(categories_one_hot, columns=mlb.classes_)

# Combine one-hot-encoded categories with BERT embeddings
combined_features = np.concatenate([batch_embeddings, categories_df.values], axis=1)

combined_df = pd.DataFrame(combined_features)
combined_df['name'] = movies_df['name']
combined_df['description'] = movies_df['description']
combined_df['image'] = movies_df['image']
combined_df['url'] = movies_df['url']

drive.mount('/content/drive')
combined_df.to_csv('/content/drive/My Drive/top_250_movie_data.csv', index=False)